{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioMouse826/Computer-Vision-CSGA-2771-/blob/main/CV_A0_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPHN7PJgKOzb"
      },
      "source": [
        "# Submit Your Early Assignment\n",
        "\n",
        "Complete the assignment by following the steps outlined below. Save and submit your work as an ipynb file when finished. You are expected to complete this assignment in under one hour.\n",
        "\n",
        "## Step 0: Download the Image from the Given URL, setting up Notebooks\n",
        "Retrieve the image from this link: [The Mysterious Painting](https://upload.wikimedia.org/wikipedia/en/7/74/PicassoGuernica.jpg)\n",
        "\n",
        "Next, go through each of the three provided notebooks. Combine them into a new notebook and configure your environment according to the specifications for the tasks below.\n",
        "\n",
        "## Step 1: Artist Recognition with the SigLip Model\n",
        "Utilize the SigLIP model(CLIP with Sigmoid activation) to identify the artist of the painting from the list of artists provided below. Display the prediction accuracy. The expected output is the artist's name, denoted as [ARTIST].\n",
        "\n",
        "Use the following Possible Artist Descriptions for zero-shot classification:\n",
        "```python\n",
        "descriptions = [\n",
        "  \"a painting by Leonardo da Vinci\",\n",
        "  \"a painting by Michelangelo\",\n",
        "  \"a painting by Vincent van Gogh\",\n",
        "  \"a painting by Pablo Picasso\",\n",
        "  \"a painting by Rembrandt\",\n",
        "  \"a painting by Claude Monet\"\n",
        "]\n",
        "```\n",
        "\n",
        "## Step 2: Style-Based Object or Scene Generation\n",
        "Once you've identified the [ARTIST], use this information to run the Stable Diffusion model. Create an object or scene (of your choice) inspired by the style of the identified artist. The output for this step should be an image, labeled as [GEN_IMAGE].\n",
        "\n",
        "## Step 3: Image Segmentation with SAM Model\n",
        "Take the generated image [GEN_IMAGE] from the previous step, and apply the SAM model for image segmentation. Present the segmentation masks. The result of this task should be a segmented image, denoted as [SEGMENT]. If you face issues such as CUDA running out of memory during SAM step, try to resize the image to a smaller scale before SAM.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: Environment Setup and Installation\n"
      ],
      "metadata": {
        "id": "CM-BrNqstboK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Set up HOME directory\n",
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)\n",
        "\n",
        "# Install all required dependencies from the three notebooks\n",
        "!pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "!pip install transformers scipy ftfy accelerate\n",
        "!pip install diffusers==0.30.2\n",
        "!pip install supervision\n",
        "!pip install opencv-python\n",
        "!pip install --upgrade -q git+https://github.com/huggingface/transformers sentencepiece\n",
        "\n",
        "# Create necessary directories\n",
        "%cd {HOME}\n",
        "!mkdir -p {HOME}/weights\n",
        "!mkdir -p {HOME}/data"
      ],
      "metadata": {
        "id": "98yJYh_vtqKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "# General imports\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from IPython.core.display import display, HTML\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# SigLIP imports\n",
        "from transformers import AutoProcessor, AutoModel, pipeline\n",
        "\n",
        "# SAM imports\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
        "import supervision as sv\n",
        "\n",
        "# Stable Diffusion imports\n",
        "from diffusers import StableDiffusionXLPipeline"
      ],
      "metadata": {
        "id": "_KZyExIZt__z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 1: Artist Recognition with SigLip model"
      ],
      "metadata": {
        "id": "MOnPj8lyu5-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SigLIP model and processor\n",
        "processor = AutoProcessor.from_pretrained(\"google/siglip-so400m-patch14-384\")\n",
        "model = AutoModel.from_pretrained(\"google/siglip-so400m-patch14-384\")\n",
        "\n",
        "# Define the possible artist descriptions\n",
        "descriptions = [\n",
        "  \"a painting by Leonardo da Vinci\",\n",
        "  \"a painting by Michelangelo\",\n",
        "  \"a painting by Vincent van Gogh\",\n",
        "  \"a painting by Pablo Picasso\",\n",
        "  \"a painting by Rembrandt\",\n",
        "  \"a painting by Claude Monet\"\n",
        "]\n",
        "\n",
        "# --- Upload your image in Colab ---\n",
        "# This code will prompt you to upload the file when run in Colab\n",
        "# Upload the PicassoGuernica.jpg into Google Colab so that the SigLip model will recognize it as \"a painting by Pablo Picasso\"\n",
        "# The output was successful in previous runs.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename (assuming you upload one file)\n",
        "image_path = list(uploaded.keys())[0]\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "display(image)  # Show the uploaded image\n",
        "\n",
        "# Prepare inputs for SigLIP\n",
        "inputs = processor(text=descriptions, images=image, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "logits_per_image = outputs.logits_per_image\n",
        "probs = torch.sigmoid(logits_per_image)  # Apply sigmoid activation\n",
        "\n",
        "# Process and display results\n",
        "text_probs = probs[0].cpu().numpy() * 100\n",
        "max_index = text_probs.argmax()\n",
        "\n",
        "print(\"Classification Results:\")\n",
        "for i, (desc, prob) in enumerate(zip(descriptions, text_probs)):\n",
        "    if i == max_index:\n",
        "        display(HTML(f\"<span style='color: red; font-weight: bold;'>{desc}: {prob:.2f}%</span>\"))\n",
        "    else:\n",
        "        print(f\"{desc}: {prob:.2f}%\")\n",
        "\n",
        "# Extract the identified artist\n",
        "identified_artist = descriptions[max_index].split(\"by \")[1]\n",
        "print(f\"\\nIdentified Artist: {identified_artist}\")\n",
        "ARTIST = identified_artist"
      ],
      "metadata": {
        "id": "yixNvMiuvA1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 2: Style-Based Generation with Stable Diffusion XL.\n",
        "\n",
        "This cell should generate a new image in the style of the identified artist."
      ],
      "metadata": {
        "id": "brMV-pN0vYfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Stable Diffusion XL pipeline\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\"\n",
        ")\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Create a prompt using the identified artist\n",
        "prompt = f\"A futuristic cityscape in the style of {ARTIST}\"\n",
        "print(f\"Generation Prompt: {prompt}\")\n",
        "\n",
        "# Generate image\n",
        "image = pipe(prompt).images[0]\n",
        "\n",
        "# Save and display the generated image\n",
        "gen_image_path = os.path.join(HOME, \"generated_image.png\")\n",
        "image.save(gen_image_path)\n",
        "display(image)\n",
        "GEN_IMAGE = gen_image_path"
      ],
      "metadata": {
        "id": "7Qa5W6vevg4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Step 3: Image Segmentation with SAM\n",
        "\n",
        "This cell segments the generated image using the Segment Anything Model."
      ],
      "metadata": {
        "id": "XoAfUyfjvknN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download SAM model weights\n",
        "%cd {HOME}/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "%cd {HOME}\n",
        "\n",
        "# Set up device\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_h\"\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
        "\n",
        "# Load SAM model\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
        "sam.to(device=DEVICE)\n",
        "\n",
        "# Create mask generator\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "\n",
        "# Load the generated image\n",
        "image_bgr = cv2.imread(GEN_IMAGE)\n",
        "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Generate masks\n",
        "sam_result = mask_generator.generate(image_rgb)\n",
        "\n",
        "# Visualize results\n",
        "mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n",
        "detections = sv.Detections.from_sam(sam_result=sam_result)\n",
        "annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n",
        "\n",
        "# Display segmentation results\n",
        "sv.plot_images_grid(\n",
        "    images=[image_bgr, annotated_image],\n",
        "    grid_size=(1, 2),\n",
        "    titles=['generated image', 'segmented image'],\n",
        "    size=(16, 8)\n",
        ")\n",
        "\n",
        "# Save segmented image\n",
        "seg_image_path = os.path.join(HOME, \"segmented_image.png\")\n",
        "cv2.imwrite(seg_image_path, annotated_image)\n",
        "SEGMENT = seg_image_path"
      ],
      "metadata": {
        "id": "vCiNrr_bvqkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Summary: This cell provides a summary of the outputs.\n",
        "\n",
        "This single notebook combining the 3 previous ipnyb files should contain the following output:\n",
        "\n",
        "Step 1: Once you uploads the PicassoGuernica.jpg file, SigLip should identify Pablo Picasso as the artist using SigLIP.\n",
        "\n",
        "Step 2: Stable Diffusion XL should generate a futuristic cityscape in Picasso's style using Stable Diffusion XL. What specifically is generated is different everytime but they share some basic features that can be identified as a Pablo Picasso painting to the naked eye.\n",
        "\n",
        "Step 3: SAM segments the previously generated image in Picasso's style using SAM into various colored blocks, polygons, fractals etc. I tested this myself in Google Colab in previous runs and it has worked thus far."
      ],
      "metadata": {
        "id": "Cy-9EikMvwbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"WORKFLOW COMPLETE!\")\n",
        "print(f\"1. Identified Artist: {ARTIST}\")\n",
        "print(f\"2. Generated Image: {GEN_IMAGE}\")\n",
        "print(f\"3. Segmented Image: {SEGMENT}\")\n",
        "\n",
        "# Display all outputs\n",
        "print(\"\\n--- Final Outputs ---\")\n",
        "display(HTML(f\"<h3>Identified Artist: {ARTIST}</h3>\"))\n",
        "\n",
        "gen_img = Image.open(GEN_IMAGE)\n",
        "display(gen_img)\n",
        "\n",
        "seg_img = cv2.imread(SEGMENT)\n",
        "seg_img_rgb = cv2.cvtColor(seg_img, cv2.COLOR_BGR2RGB)\n",
        "display(Image.fromarray(seg_img_rgb))"
      ],
      "metadata": {
        "id": "9au5AOOHwzEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T8Eiv_eVvENv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}